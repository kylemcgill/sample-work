import os
import numpy as np
import scipy.stats as stats
import pandas as pd
import matplotlib.pyplot as plt
import const
import math

def fillNa(chunk, rules, ruleTypes='columns'):
    '''
    Takes a chunk and fills the N/a values of each col with 
    user supplied rules

    chunk = The dictionary to iterate over

    rules = dict of what to do for each item

    rules_type = 'columns' or 'dtype' to reda the rules dict
    '''

    if ruleTypes == 'columns':
        for col in chunk:
            if col in rules:
                if chunk[col].dtype == 'Category':
                    pass # n/a will be its own category
                else:
                    #[0]=mean, [1]=stdev
                    chunk[col] = chunk[col].fillna(np.random.normal(rules[0], rules[1]))
            else:
                print(f'Column is not in rules: {col}')
                return None
    elif ruleTypes == 'dtype':
        pass
    # 'chunk' is a dict where key='col_name'
    # Need to handle N/A values
    for col in chunk:
        if chunk[col].dtype == 'Category':
            pass #
        elif chunk[col].dtype == 'int8':
            pass
        elif chunk[col].dtype == 'int16':
            pass
        elif chunk[col].dtype == 'int32':
            pass
        elif chunk[col].dtype == 'int64':
            pass
        elif chunk[col].dtype == 'float16':
            pass
        elif chunk[col].dtype == 'float32':
            pass
        elif chunk[col].dtype == 'float64':
            pass
        else:
            print(f'Unhandled case: {chunk[col].dtype}')
            quit()

    # Write out the preprocessed data to new file

def columnDecision(indir, outdir, df_dtypes):
    '''
    This iterates through the column files and prints out some helpful 
    stats about the column.  Then asks user whether to add it to the 
    use_col.txt file

    indir = where all the column files are located

    outdir = place to put the outfile
    '''
    outfile = 'use_col.txt'
    files = os.listdir(indir)
    
    # First need to read the 'hasDetections' file
    detections_df = pd.read_csv(indir + 'HasDetections.csv', dtype=df_dtypes)
    print(detections_df.dtypes)    
    has_detections_str = 'HasDetections'

    # Second need to iterate through all the files and append the detections to the 
    # dataframe we create with the current column.
    count = 0
    for filename in os.listdir(indir):
        print(f'Working with file: {filename}...')
        col_name = filename.split(".")[0]
        # print(col_name)
        
        current_df = pd.read_csv(indir + filename)
        current_df = pd.concat([current_df, detections_df], axis=1)
        if col_name in df_dtypes:
            # print(f'Setting {col_name} to dtype: {df_dtypes[col_name]}')
            current_df = current_df.astype({col_name : df_dtypes[col_name]}) # astype() returns the new data frame
        else:
            print(f'Column \'{col_name}\' not in \'df_dtypes\'')
            quit()
        # print(current_df[col_name])
        
        # Get some basic stats
        length_col = len(current_df[col_name])

        # Check the NaN values
        n_nan = current_df[col_name].isna().sum()
        print(f'Total number of NaN:\t{n_nan}\t{n_nan/length_col:2.2%}')

        # split into 2 groups 'hasDetections' and not
        true_df = current_df[current_df[has_detections_str] == 1]
        false_df = current_df[current_df[has_detections_str] == 0]

        print(df_dtypes[col_name])
        if df_dtypes[col_name] == 'category':
            printCategoryStats(true_df, false_df, current_df, col_name)
        else:
            printNumericalStats(true_df, false_df, current_df, col_name)
        # plot = createCatPlots(plot_data)

        # Ask the user whether to put col into use file
        # Put all files into file but with 1 or 0 depending
        # if we want to use it or not.
        write_mode = 'a'
        if count == 0:
            write_mode = 'w'

        with open(outdir + outfile, mode=write_mode):
            while True:
                txt = input('Use column in model [Y/n]? ')
                if (txt == 'Y') | (txt == 'yes') | (txt == 'Yes') | (txt == 'y'):
                    break
                elif(txt == 'N') | (txt == 'n') | (txt == 'no') | (txt == 'No'):
                    break
                elif (txt == 'plot') | (txt =='p'):
                    # plot.show()
                    continue
                else:
                    print('Please write \'yes\' or \'no\'!')
                    continue
        print('#'*40)
        count += 1

    print(files)


    return
# END COLUMN DECISION

def unitTestOneColumn(unit_file, df_types, arguments):
    # First need to read the 'hasDetections' file
    detections_df = pd.read_csv(const.constants.detections_filename, dtype=df_types)
    print(detections_df.dtypes)    
    has_detections_str = 'HasDetections'

    #Load the unit_file we wnat to test
    current_df = pd.read_csv(const.constants.indir + unit_file)
    col_name = unit_file.split('.')[0]
    print(f'Stripped col_name: {col_name}')
   
    # If we don't have the col_name maped then we should not process it
    # TODO: Maybe to infrencing here if we don't find it?
    if col_name not in df_types:
        print(f'{col_name} is not in the dtype map! Exiting...')
        return

    if arguments.verbose:
        print(f'col_name dtype: {df_types[col_name]}')
    
    # Concatinate the columns to make processing easier
    current_df = pd.concat([current_df, detections_df], axis=1)

    # split into 2 groups 'hasDetections' and not
    true_df = current_df[current_df[has_detections_str] == 1]
    false_df = current_df[current_df[has_detections_str] == 0]

    # For all columns we need to check how many n/a's there are and if there 
    # is a significant difference between true and false. If there is, then we 
    # might be able to use n/a as it's own category.
    na_total = current_df[col_name].isna().sum()
    na_true = true_df[col_name].isna().sum()
    na_false = false_df[col_name].isna().sum()
    if arguments.verbose:
        print(f'na_total: {na_total}\nna_true: {na_true}\nna_false:{na_false}')
            
    # Since we run into problems with NaN values when getting distributions, 
    # replace the NaN values with some other string which doesn't have the
    # NaN value associated with it.
    not_set_str = 'SET_NOT'
    current_df = current_df.fillna(not_set_str)
    true_df = true_df.fillna(not_set_str)
    false_df = false_df.fillna(not_set_str)

    current_dtype = df_types[col_name]
    if current_dtype == 'category':
        if arguments.pre_process:
            # TODO: Move distributions into here for release
            pass
        if arguments.plot:
            # TODO: Move plotting into here for release
            pass
        if arguments.interactive:
            # TODO: Move terminal decision into here for release
            pass

        # Distribution
        categoryDistribution(true_df, false_df, current_df, col_name, arguments)
        chiSquareTest(true_df, false_df, current_df, col_name, arguments)
        # Plot TODO: use this example to plot the histograms
        '''
        ax = current_df.plot.hist()
        plt.show()
        '''
        # Decision
    elif (current_dtype == 'int8') | (current_dtype == 'int16') | (current_dtype == 'int32') | (current_dtype == 'int64'):
        #TODO: Call both the 'numerical' and 'categorical' preprocess
        if arguments.pre_process:
            # TODO: Move distributions into here for release
            pass
        if arguments.plot:
            # TODO: Move plotting into here for release
            pass
        if arguments.interactive:
            # TODO: Move terminal decision into here for release
            pass
        
        # Distribution
        categoryDistribution(true_df, false_df, current_df, col_name, arguments)
        chiSquareTest(true_df, false_df, current_df, col_name, arguments)
        # Plot
        # Decision

    else:
        if arguments.pre_process:
            # TODO: Move distributions into here for release
            pass
        if arguments.plot:
            # TODO: Move plotting into here for release
            pass
        if arguments.interactive:
            # TODO: Move terminal decision into here for release
            pass
        
        # Distibution
        numericalDistribution(true_df, false_df, current_df, col_name, arguments)
        # Multiple Mode?
        number_of_modes = numericalMultipleMode(true_df, false_df, current_df, col_name, arguments)
        # t-test if normal
        if number_of_modes == 1:
            tTest(true_df, false_df, current_df, col_name, arguments)
        elif number_of_modes == 0:
            print(f'There was an error in determining number of modes!')
        # Plot

    return

def numericalDistribution(true_df, false_df, current_df, col_name, arguments):
    '''
    Prints out the distibution of numerical data for the set of true's
    false's and all data points.

    true_df = the set of machines with HasDetections == 1

    false_df = the set of machines with HasDetections == 0

    current_df = all machines in the data set

    col_name = the name of the x-column for quick access
    
    arguments = the options passed into the program
    '''
    print('-'*60)
    print(f'True_df description:')
    print(true_df.describe())
    print('-'*15)
    print(f'false_df description:')
    print(false_df.describe())
    print('-'*15)
    print(f'current_df description:')
    print(current_df.describe())


def numericalMultipleMode(true_df, false_df, current_df, col_name, arguments):
    '''
    Prints out the distibution of numerical data after binning for the set of true's
    false's and all data points. Returns the number of detected modes.

    true_df = the set of machines with HasDetections == 1

    false_df = the set of machines with HasDetections == 0

    current_df = all machines in the data set

    col_name = the name of the x-column for quick access
    
    arguments = the options passed into the program

    RETURNS the number of detected modes
    '''

    return 0

def tTest(true_df, false_df, current_df, col_name, arguments):
    '''
    Performs a t-test between the true and false dfs to determine 
    how similar the distributions are. The null hypothesis is both
    true and false should have the same distribution.

    true_df = the set of machines with HasDetections == 1

    false_df = the set of machines with HasDetections == 0

    current_df = all machines in the data set

    col_name = the name of the x-column for quick access
    
    arguments = the options passed into the program
    '''
    pass

def categoryDistribution(true_df, false_df, current_df, col_name, arguments):
    '''
    Prints out the distibution of categorical data for the set of true's
    false's and all data points.

    true_df = the set of machines with HasDetections == 1

    false_df = the set of machines with HasDetections == 0

    current_df = all machines in the data set

    col_name = the name of the x-column for quick access
    
    arguments = the options passed into the program
    '''
    category_list = current_df[col_name].unique()
    if arguments.verbose:
        print(f'Unique categories for column {col_name}:')
        for cat in category_list:
            print(f'\t{cat}')
    
    true_cat_dist = getDistribution(true_df, category_list, col_name)
    false_cat_dist = getDistribution(false_df, category_list, col_name)
    current_cat_dist = getDistribution(current_df, category_list, col_name)

    # Print out the distributions in a formatted table 
    # TODO: Sort the table in decending order 
    max_str_len = 0
    for cat in category_list:
        if len(str(cat)) > max_str_len:
            max_str_len = len(str(cat))
    if arguments.verbose:
        print(f'Found max_str_len to be {max_str_len}')

    # Add some padding 
    max_str_len += 3
    
    # Print out the data
    print(f'-'*40)
    print(f'Column name: {col_name}\n')
    header = ['Category','true_df','false_df','current_df']
    print(header[0].ljust(max_str_len), header[1].rjust(10), header[2].rjust(10), header[3].rjust(10))
    print(f'-'*(max_str_len + 30))
    for cat in category_list:
        print(str(cat).ljust(max_str_len), end='')
        print(f'{true_cat_dist[cat]:>10.2%}{false_cat_dist[cat]:>10.2%}{current_cat_dist[cat]:>10.2%}')
    print(f'-'*(max_str_len + 30))

def getDistribution(df, category_list, col_name):
    '''
    Returns a dict with key=category_str and value=percent_value_distribution.
    User supplies the category_list since some may not be present in subset.
    '''
    cat_counts = {k: len(df[df[col_name] == k]) for k in category_list}
    len_df = len(df.index)
    df_cat_dist = {k: (cat_counts[k]/len_df) for k in category_list}
    return df_cat_dist


def chiSquareTest(true_df, false_df, current_df, col_name, arguments):
    '''
    Performs a chi-square test for significance on the column data. Assumes 
    the null hypothesis distibution is the distribution of the current_df, while 
    the true and false subsets are being tested against the null.

    true_df = the set of machines with HasDetections == 1

    false_df = the set of machines with HasDetections == 0

    current_df = all machines in the data set

    col_name = the name of the x-column for quick access
    
    arguments = the options passed into the program
    '''

    # Get the initial distribution data
    category_list = current_df[col_name].unique()
    if arguments.verbose:
        print(f'Unique categories for column {col_name}:')
        for cat in category_list:
            print(f'\t{cat}')
    
    # Bottom margin of table
    n_total = len(current_df.index)
    n_true = len(true_df.index)
    n_false = len(false_df.index)

    # Total count for each category; aka right margin of table
    n_cat = {k: len(current_df[current_df[col_name] == k]) for k in category_list}

    # Observed frequencies 
    n_cat_each_observed = {k: [len(true_df[true_df[col_name] == k]),
                                len(false_df[false_df[col_name] == k])] 
                                for k in category_list
                          }
    if arguments.verbose:
        cat_max_str_len = 0
        n = 10
        for cat in category_list: 
            if len(str(cat)) > cat_max_str_len: 
                cat_max_str_len = len(str(cat))
        cat_max_str_len += 3
        print('-'*(cat_max_str_len+30))
        header = ['Category', 'true_df', 'false_df', 'current_df']
        print(header[0].ljust(cat_max_str_len), header[1].rjust(n), header[2].rjust(n), header[3].rjust(n)) 
        for cat in n_cat_each_observed:
            print(str(cat).ljust(cat_max_str_len), 
                    repr(n_cat_each_observed[cat][0]).rjust(n)[:n],
                    repr(n_cat_each_observed[cat][1]).rjust(n)[:n],
                    repr(n_cat[cat]).rjust(n)
                )
    
    # Expected Frequencies
    # %_current_cat_dist * (n_true | n_false); Expect the same dist as current for both true and false
    n_cat_each_expected = {k: [(n_cat[k]/n_total * n_true), 
                                (n_cat[k]/n_total * n_false)] 
                                for k in category_list
                          }
    if arguments.verbose:
        cat_max_str_len = 0
        n = 10
        for cat in category_list: 
            if len(str(cat)) > cat_max_str_len: 
                cat_max_str_len = len(str(cat))
        cat_max_str_len += 3
        print('-'*(cat_max_str_len+30))
        header = ['Category', 'true_df', 'false_df', 'current_df']
        print(header[0].ljust(cat_max_str_len), header[1].rjust(n), header[2].rjust(n), header[3].rjust(n)) 
        for cat in n_cat_each_observed:
            print(str(cat).ljust(cat_max_str_len), 
                    repr(n_cat_each_expected[cat][0]).ljust(n)[:n],
                    repr(n_cat_each_expected[cat][1]).ljust(n)[:n],
                    repr(n_cat[cat]).rjust(n)
                )
        print('Total'.ljust(cat_max_str_len),
                repr(n_true).rjust(n),
                repr(n_false).rjust(n),
                repr(n_total).rjust(n)
            )


    # Get (observed - expected)^2 / expected
    error_matrix = {k: [(math.pow((n_cat_each_observed[k][0] - n_cat_each_expected[k][0]),2) / n_cat_each_expected[k][0]),
                        (math.pow((n_cat_each_observed[k][1] - n_cat_each_expected[k][1]),2) / n_cat_each_expected[k][1])]
                        for k in category_list
                    }
    if arguments.verbose:
        cat_max_str_len = 0
        n = 10
        for cat in category_list: 
            if len(str(cat)) > cat_max_str_len: 
                cat_max_str_len = len(str(cat))
        cat_max_str_len += 3
        print('-'*(cat_max_str_len+30))
        header = ['Category', 'true_df', 'false_df', 'current_df']
        print(header[0].ljust(cat_max_str_len), header[1].rjust(n), header[2].rjust(n), header[3].rjust(n)) 
        for cat in n_cat_each_observed:
            print(str(cat).ljust(cat_max_str_len), 
                    repr(error_matrix[cat][0]).ljust(n)[:n],
                    repr(error_matrix[cat][1]).ljust(n)[:n],
                    repr(n_cat[cat]).rjust(n)[:n]
                )

    # Sum the error matrix
    chi_square_stat = 0
    for cat in error_matrix:
        for element in error_matrix[cat]:
            chi_square_stat += element
    
    print(f'Chi-square stat is: {chi_square_stat}')

    # Degrees of freedom for chi-square
    degrees_of_freedom = (len(category_list) -1) *(2 -1)

    p_stat = stats.chi2.cdf(chi_square_stat, degrees_of_freedom)
    print(f'\np-statistic for col {col_name}: {1-p_stat:.4f}')

    # Get the percentile and print ot screen
def categoryPlot(true_df, false_df, current_df):
    pass


def createCatPlots(cat_data):
    '''
    Takes a dict of categoies and their respective lists of data
    and returns a plot object which we can show whenever we want.

    cat_data = dict of key=category<xaxis> and value='list of
                numerical data to plot'<yaxis>

    RETURNS matplotlib plot without showing it first
    '''
    n_ind = np.arange(len(cat_data)) # number of indicies we have
    width = 0.35 # the width of bars

    fig,ax = plt.subplots()
    rearange = [ [0 for j in range(0,len(cat_data.keys()))] for i in range(0, 3)]
    print(rearange)
    for cat in cat_data:
        print(cat_data[cat])

    count = 0
    for cat in cat_data:
        for i in range(0,3):
            rearange[i][count] = cat_data[cat][i]
        count += 1
    count = 0
    
    true_rect =  ax.bar(n_ind-width/3, rearange[0], width, color='SkyBlue', label='True')
    false_rect =  ax.bar(n_ind-width/3, rearange[1], width, color='IndianRed', label='False')
    all_rect = ax.bar(n_ind-width/3, rearange[2], width, color='Green', label='All')

    ax.set_ylabel('Percent')
    ax.set_title('Percent distribution of Categories')
    ax.set_xticks(n_ind)
    ax.set_xticklabels(list(cat_data.keys()))
    ax.legend()

    autolabel(true_rect, "left", ax)
    autolabel(false_rect, "center", ax)
    autolabel(all_rect, "right", ax)

    return plt


def autolabel(rects, xpos='center', ax=None):
    '''
    Attach a text label above each bar in *rects*, displaying its height.

    *xpos* indicates which side to place the text w.r.t. the center of
    the bar. It can be one of the following {'center', 'right', 'left'}.
    '''

    xpos = xpos.lower()  # normalize the case of the parameter
    ha = {'center': 'center', 'right': 'left', 'left': 'right'}
    offset = {'center': 0.5, 'right': 0.57, 'left': 0.43}  # x_txt = x + w*off

    for rect in rects:
        height = rect.get_height()
        ax.text(rect.get_x() + rect.get_width()*offset[xpos], 1.01*height,
                '{}'.format(height), ha=ha[xpos], va='bottom')


def printCategoryStats(true_df, false_df, current_df, col_name):
    '''
    Prints out stats relevant to Category type columns.

    true_df = data frame that contains only HasDetections=true machines

    false_df = data frame that contains only HasDetections=false machines

    current_df = data frame that has all machines in it.

    col_name = string version of the current column we are working with

    RETURNS None
    '''
    
    categories_list = current_df[col_name].unique()
    print(f'Unique items: {categories_list}')

    # print distribution of category or number for each group
    #   Category should do percent of each
    #   numbers should give histogram        
    print('-'*40)
    print(true_df.head(3))
    plot_data = {k: [] for k in categories_list} # 'value' for 'iterator' in 'iterable'
    for cat in categories_list:
        # get instances of cat
        n_cat = len(true_df[true_df[col_name] == cat])
        cat_percent = n_cat/len(true_df)
        plot_data[cat].append(cat_percent)
    print('-'*40)

    for cat in categories_list:
        # get instances of cat
        n_cat = len(false_df[false_df[col_name] == cat])
        cat_percent = n_cat/len(false_df)
        plot_data[cat].append(cat_percent)

    # print distribution of combined both groups
    #   Idea being is that if the distributions are the same as 
    #   then there is no explanitory power of the variable
    print('-'*40)
    for cat in categories_list:
        # get instances of cat
        n_cat = len(current_df[current_df[col_name] == cat])  
        cat_percent = n_cat/len(current_df)
        plot_data[cat].append(cat_percent)

    # formatted print
    header_items = ['Category','true_df','false_df','current_df']
    print(f'{header_items[0]:<15}{header_items[1]:>15}{header_items[2]:>15}{header_items[3]:>15}')
    print('-'*(15*len(header_items)))
    format_str = '>15.2%'
    for cat in plot_data:
        # '%' is a format symbol which converts the float to a percent format
        print('{:<15s}{:>15.2%}{:>15.2%}{:>15.2%}'.format(cat, plot_data[cat][0],plot_data[cat][1],plot_data[cat][2]))

    # Probably do something like a chi-square test for categories
    #   -The expected probablity would be the count in current_df
    #       divided by 2 if assume there is no explanitory value 
    #       in the column.
    #   -The two vars are the category and HasDetections
    #   -Degrees of freedom = (n_categories - 1)*(n_detections - 1)
    # Scipy.stats.chisquared takes an array that is column major
    

        


def printNumericalStats(true_df, false_df, current_df, col_name):
    '''
    Prints numerical description of the data to the terminal. Things
    we want to show the user are:
        - Min value
        - Max Value
        - median
        - mode
        - mean 
        - 25%, 50%, 75%
    
    Goal is to see if distributions are inherintly different between 
    the true_df and false_df. Ideally we run a t-test or something to
    test for significance.

    true_df = the machines which have detections
    false_df = the machines which have no detections 
    current_df = the entire set
    '''

    print(f'True df:\n', true_df.describe())
    print(f'False df:\n', false_df.describe())
    print(f'Current df:\n', current_df.describe())
    